{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b60619a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88934da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        hidden = [400, 300, 200, 100]\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden[0],\n",
    "                             batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(2 * hidden[3], 50)\n",
    "        self.conv= nn.Conv1d(5,5,3)\n",
    "        self.embedding=nn.Embedding(10,5)\n",
    "        \n",
    "        self._reinitialize() ## reinitialize here like tf.keras\n",
    "\n",
    "    def _reinitialize(self):\n",
    "        \"\"\"\n",
    "        Tensorflow/Keras-like initialization\n",
    "        \"\"\"\n",
    "        for _, p in self.named_children():\n",
    "            if 'LSTM' in p.__str__():\n",
    "                for name,q in p.named_parameters():\n",
    "                    if 'weight_ih' in name:\n",
    "                        nn.init.xavier_uniform_(q.data)\n",
    "                    elif 'weight_hh' in name:\n",
    "                        nn.init.orthogonal_(q.data)\n",
    "                    elif 'bias_ih' in name:\n",
    "                        q.data.fill_(0)\n",
    "                        #Set forget-gate bias to 1\n",
    "                        n=q.size(0)\n",
    "                        q.data[(n // 4):(n // 2)].fill_(1)\n",
    "                    elif 'bias_hh' in name:\n",
    "                        q.data.fill_(0)\n",
    "            elif 'Conv' in p.__str__():\n",
    "                for name,q in p.named_parameters():\n",
    "                    if 'weight' in name:\n",
    "                        nn.init.xavier_uniform_(q.data)\n",
    "                    elif 'bias' in name:\n",
    "                        q.data.fill_(0)\n",
    "                    \n",
    "            elif 'Linear' in p.__str__():\n",
    "                for name,q in p.named_parameters():\n",
    "                    if 'weight' in name:\n",
    "                        nn.init.xavier_uniform_(q.data)\n",
    "                    elif 'bias' in name:\n",
    "                        q.data.fill_(0)\n",
    "                    \n",
    "\n",
    "            elif 'Embedding' in p.__str__():\n",
    "                for name,q in p.named_parameters():\n",
    "                    nn.init.uniform_(q.data)\n",
    "                \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e743f644",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo=Model(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5801e3e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lstm.weight_ih_l0': Parameter containing:\n",
       " tensor([[-0.0496,  0.0243,  0.0591,  ..., -0.0284, -0.0282, -0.0545],\n",
       "         [-0.0168, -0.0151,  0.0445,  ...,  0.0142, -0.0530, -0.0249],\n",
       "         [-0.0314,  0.0025,  0.0100,  ...,  0.0119,  0.0601,  0.0406],\n",
       "         ...,\n",
       "         [ 0.0417, -0.0555,  0.0596,  ...,  0.0439,  0.0476, -0.0183],\n",
       "         [-0.0358,  0.0194,  0.0495,  ...,  0.0288,  0.0383, -0.0099],\n",
       "         [-0.0314,  0.0598, -0.0213,  ..., -0.0582,  0.0532, -0.0245]],\n",
       "        requires_grad=True),\n",
       " 'lstm.weight_hh_l0': Parameter containing:\n",
       " tensor([[ 0.0305, -0.0203, -0.0168,  ...,  0.0139,  0.0022, -0.0011],\n",
       "         [-0.0209,  0.0060,  0.0437,  ..., -0.0059,  0.0314, -0.0211],\n",
       "         [-0.0040,  0.0184,  0.0083,  ..., -0.0195, -0.0033, -0.0023],\n",
       "         ...,\n",
       "         [-0.0082,  0.0047, -0.0270,  ..., -0.0006, -0.0139, -0.0477],\n",
       "         [-0.0324, -0.0311,  0.0126,  ..., -0.0478, -0.0012,  0.0163],\n",
       "         [ 0.0224,  0.0464, -0.0033,  ...,  0.0172, -0.0007,  0.0016]],\n",
       "        requires_grad=True),\n",
       " 'lstm.bias_ih_l0': Parameter containing:\n",
       " tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True),\n",
       " 'lstm.bias_hh_l0': Parameter containing:\n",
       " tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True),\n",
       " 'lstm.weight_ih_l0_reverse': Parameter containing:\n",
       " tensor([[-0.0174, -0.0059,  0.0578,  ..., -0.0394, -0.0312,  0.0518],\n",
       "         [ 0.0330,  0.0062, -0.0279,  ...,  0.0085,  0.0082,  0.0129],\n",
       "         [-0.0516,  0.0225, -0.0344,  ...,  0.0471, -0.0182, -0.0185],\n",
       "         ...,\n",
       "         [-0.0203,  0.0151,  0.0480,  ...,  0.0228, -0.0066,  0.0505],\n",
       "         [ 0.0555,  0.0233,  0.0449,  ...,  0.0542,  0.0316,  0.0114],\n",
       "         [ 0.0074, -0.0101,  0.0029,  ...,  0.0598, -0.0551, -0.0299]],\n",
       "        requires_grad=True),\n",
       " 'lstm.weight_hh_l0_reverse': Parameter containing:\n",
       " tensor([[ 0.0143,  0.0062,  0.0526,  ..., -0.0015, -0.0092, -0.0367],\n",
       "         [-0.0039, -0.0056,  0.0306,  ...,  0.0295,  0.0196, -0.0419],\n",
       "         [ 0.0507, -0.0409,  0.0096,  ...,  0.0096, -0.0078, -0.0292],\n",
       "         ...,\n",
       "         [ 0.0450,  0.0010, -0.0083,  ..., -0.0339,  0.0181, -0.0469],\n",
       "         [ 0.0313,  0.0740, -0.0234,  ...,  0.0377, -0.0148, -0.0510],\n",
       "         [-0.0402,  0.0020,  0.0242,  ...,  0.0156,  0.0104,  0.0071]],\n",
       "        requires_grad=True),\n",
       " 'lstm.bias_ih_l0_reverse': Parameter containing:\n",
       " tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True),\n",
       " 'lstm.bias_hh_l0_reverse': Parameter containing:\n",
       " tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True),\n",
       " 'fc.weight': Parameter containing:\n",
       " tensor([[ 0.0571,  0.0060, -0.0934,  ..., -0.1312,  0.0353,  0.0809],\n",
       "         [ 0.0606,  0.1267,  0.1212,  ...,  0.0929, -0.1313, -0.0946],\n",
       "         [ 0.0627, -0.0519, -0.1478,  ..., -0.1027,  0.0553, -0.1300],\n",
       "         ...,\n",
       "         [-0.0705,  0.0425, -0.1090,  ...,  0.1059, -0.0581, -0.1151],\n",
       "         [ 0.1441,  0.1060, -0.1083,  ..., -0.0642,  0.1328, -0.0778],\n",
       "         [-0.0978,  0.0890,  0.0811,  ..., -0.0283, -0.0706, -0.1216]],\n",
       "        requires_grad=True),\n",
       " 'fc.bias': Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.], requires_grad=True),\n",
       " 'conv.weight': Parameter containing:\n",
       " tensor([[[-0.0256,  0.3742,  0.3643],\n",
       "          [ 0.1284, -0.4339, -0.2512],\n",
       "          [ 0.0570,  0.0280,  0.1313],\n",
       "          [ 0.3907, -0.1852, -0.0748],\n",
       "          [-0.0998,  0.1865, -0.0727]],\n",
       " \n",
       "         [[-0.0885,  0.1999, -0.4184],\n",
       "          [ 0.2377,  0.1493,  0.1885],\n",
       "          [-0.3111, -0.3766,  0.3414],\n",
       "          [ 0.4310,  0.1855,  0.1362],\n",
       "          [ 0.3971,  0.1063,  0.1429]],\n",
       " \n",
       "         [[-0.2745,  0.2230, -0.2353],\n",
       "          [ 0.2580, -0.3303,  0.0804],\n",
       "          [-0.1405,  0.2998, -0.3794],\n",
       "          [-0.3009, -0.2865, -0.3935],\n",
       "          [-0.2535,  0.2437, -0.3351]],\n",
       " \n",
       "         [[-0.0647, -0.0802,  0.3040],\n",
       "          [ 0.3222, -0.2629,  0.3633],\n",
       "          [ 0.0858, -0.4409, -0.0358],\n",
       "          [-0.0814, -0.1162, -0.1617],\n",
       "          [-0.1522,  0.1415,  0.1452]],\n",
       " \n",
       "         [[-0.2009, -0.2534,  0.2237],\n",
       "          [-0.0735,  0.3061,  0.4170],\n",
       "          [-0.1745,  0.0872, -0.3196],\n",
       "          [-0.0330,  0.1315,  0.0712],\n",
       "          [-0.4106, -0.2714,  0.4054]]], requires_grad=True),\n",
       " 'conv.bias': Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0.], requires_grad=True),\n",
       " 'embedding.weight': Parameter containing:\n",
       " tensor([[0.0538, 0.8490, 0.2064, 0.2306, 0.7462],\n",
       "         [0.3655, 0.3704, 0.6173, 0.8783, 0.1253],\n",
       "         [0.4146, 0.5977, 0.5004, 0.7905, 0.5234],\n",
       "         [0.5299, 0.0154, 0.2458, 0.9568, 0.7267],\n",
       "         [0.3188, 0.7083, 0.1198, 0.1602, 0.4803],\n",
       "         [0.3637, 0.5532, 0.0633, 0.3549, 0.0212],\n",
       "         [0.4956, 0.6329, 0.0909, 0.0187, 0.6115],\n",
       "         [0.2700, 0.6720, 0.5055, 0.6987, 0.1989],\n",
       "         [0.8515, 0.7911, 0.6394, 0.4519, 0.2723],\n",
       "         [0.8606, 0.3089, 0.6195, 0.2963, 0.6027]], requires_grad=True)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(demo.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f8fa54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
